"""
é—®é¢˜éš¾åº¦åˆ¤æ–­å™¨
åˆ†æé—®é¢˜å¤æ‚åº¦å¹¶å†³å®šæ€è€ƒè·¯çº¿æ•°é‡
"""

import re
import logging
from typing import Dict, List, Tuple
from .config import TREE_THINKING_CONFIG, COMPLEX_KEYWORDS, BRANCH_TYPES

logger = logging.getLogger("DifficultyJudge")

class DifficultyJudge:
    """é—®é¢˜éš¾åº¦åˆ¤æ–­å™¨"""
    
    def __init__(self, api_client=None):
        self.api_client = api_client
        self.config = TREE_THINKING_CONFIG
        self.complex_keywords = COMPLEX_KEYWORDS
        
        # éš¾åº¦è¯„ä¼°æƒé‡
        self.weights = {
            "length": 0.15,           # æ–‡æœ¬é•¿åº¦
            "keywords": 0.25,         # å…³é”®è¯åŒ¹é…
            "sentence_structure": 0.20, # å¥å¼å¤æ‚åº¦
            "question_type": 0.25,    # é—®é¢˜ç±»å‹
            "ai_assessment": 0.15     # AIæ·±åº¦è¯„ä¼°
        }
        
        print("[TreeThinkingEngine] ğŸ¯ é—®é¢˜éš¾åº¦åˆ¤æ–­å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def assess_difficulty(self, question: str) -> Dict:
        """è¯„ä¼°é—®é¢˜éš¾åº¦"""
        try:
            # åŸºç¡€æŒ‡æ ‡è®¡ç®—
            text_metrics = self._analyze_text_metrics(question)
            keyword_metrics = self._analyze_keywords(question)
            structure_metrics = self._analyze_structure(question)
            
            # AIæ·±åº¦è¯„ä¼°ï¼ˆä¼˜å…ˆä½¿ç”¨å¿«é€Ÿæ¨¡å‹ï¼‰
            ai_metrics = await self._ai_deep_assessment(question)
            
            # ç»¼åˆè¯„åˆ†
            final_score = self._calculate_final_score(
                question, text_metrics, keyword_metrics, structure_metrics, ai_metrics
            )
            
            difficulty = min(5, max(1, round(final_score)))
            routes = self.config["difficulty_routes"][difficulty]
            
            # ç”Ÿæˆæ¨ç†è¯´æ˜
            reasoning = self._generate_reasoning(
                difficulty, text_metrics, keyword_metrics, structure_metrics, ai_metrics
            )
            
            logger.info(f"é—®é¢˜éš¾åº¦è¯„ä¼°å®Œæˆ: éš¾åº¦{difficulty}/5, {routes}æ¡æ€è€ƒè·¯çº¿")
            
            return {
                "difficulty": difficulty,
                "routes": routes,
                "reasoning": reasoning,
                "metrics": {
                    "text": text_metrics,
                    "keywords": keyword_metrics,
                    "structure": structure_metrics,
                    "ai_assessment": ai_metrics
                }
            }
            
        except Exception as e:
            logger.error(f"éš¾åº¦è¯„ä¼°å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤éš¾åº¦
            return {
                "difficulty": 3,
                "routes": 5,
                "reasoning": f"éš¾åº¦è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {str(e)}",
                "metrics": {}
            }
    
    def _analyze_text_metrics(self, question: str) -> float:
        """åˆ†ææ–‡æœ¬é•¿åº¦å¤æ‚åº¦"""
        length = len(question)
        
        if length < 20:
            return 1.0  # å¾ˆç®€å•
        elif length < 50:
            return 2.0  # ç®€å•
        elif length < 100:
            return 3.0  # ä¸­ç­‰
        elif length < 200:
            return 4.0  # å¤æ‚
        else:
            return 5.0  # å¾ˆå¤æ‚
    
    def _analyze_keywords(self, question: str) -> float:
        """åˆ†æå…³é”®è¯å¤æ‚åº¦"""
        detected_keywords = self._extract_keywords(question)
        keyword_count = len(detected_keywords)
        
        # æ ¹æ®å…³é”®è¯æ•°é‡è¯„åˆ†
        if keyword_count == 0:
            return 1.0
        elif keyword_count <= 2:
            return 2.5
        elif keyword_count <= 4:
            return 3.5
        elif keyword_count <= 6:
            return 4.5
        else:
            return 5.0
    
    def _extract_keywords(self, question: str) -> List[str]:
        """æå–é—®é¢˜ä¸­çš„å¤æ‚å…³é”®è¯"""
        detected = []
        for keyword in self.complex_keywords:
            if keyword in question:
                detected.append(keyword)
        return detected
    
    def _analyze_structure(self, question: str) -> float:
        """åˆ†æå¥å¼ç»“æ„å¤æ‚åº¦"""
        # æ£€æŸ¥æ ‡ç‚¹ç¬¦å·å¤æ‚åº¦
        comma_count = question.count(',') + question.count('ï¼Œ')
        semicolon_count = question.count(';') + question.count('ï¼›')
        question_marks = question.count('?') + question.count('ï¼Ÿ')
        
        # æ£€æŸ¥è¿æ¥è¯
        connectives = ['ç„¶è€Œ', 'ä½†æ˜¯', 'å› æ­¤', 'æ‰€ä»¥', 'ç”±äº', 'å¦‚æœ', 'è™½ç„¶', 'å°½ç®¡']
        connective_count = sum(1 for conn in connectives if conn in question)
        
        # è®¡ç®—å¤æ‚åº¦åˆ†æ•°
        complexity = (comma_count * 0.5 + semicolon_count * 1.0 + 
                     question_marks * 0.5 + connective_count * 1.0)
        
        if complexity < 1:
            return 1.5
        elif complexity < 3:
            return 2.5
        elif complexity < 5:
            return 3.5
        elif complexity < 8:
            return 4.5
        else:
            return 5.0
    
    def _assess_question_type(self, question: str) -> float:
        """è¯„ä¼°é—®é¢˜ç±»å‹å¤æ‚åº¦"""
        # ä¸åŒç±»å‹é—®é¢˜çš„å¤æ‚åº¦æ˜ å°„
        type_patterns = {
            r'ä»€ä¹ˆ|æ˜¯ä»€ä¹ˆ|æ€ä¹ˆæ ·': 1.5,      # åŸºç¡€äº‹å®ç±»
            r'å¦‚ä½•|æ€ä¹ˆåš|æ–¹æ³•': 3.0,        # æ–¹æ³•æŒ‡å¯¼ç±»
            r'ä¸ºä»€ä¹ˆ|åŸå› |åˆ†æ': 3.5,        # åˆ†æè§£é‡Šç±»
            r'æ¯”è¾ƒ|å¯¹æ¯”|åŒºåˆ«': 4.0,          # æ¯”è¾ƒè¯„ä¼°ç±»
            r'è®¾è®¡|ä¼˜åŒ–|æ”¹è¿›|æ–¹æ¡ˆ': 4.5,     # è®¾è®¡ä¼˜åŒ–ç±»
            r'è¯„ä¼°|åˆ¤æ–­|é€‰æ‹©|å†³ç­–': 4.5,     # å†³ç­–åˆ¤æ–­ç±»
            r'åˆ›æ–°|åˆ›é€ |å‘æ˜': 5.0           # åˆ›æ–°åˆ›é€ ç±»
        }
        
        max_score = 1.0
        for pattern, score in type_patterns.items():
            if re.search(pattern, question):
                max_score = max(max_score, score)
        
        return max_score
    
    async def _ai_deep_assessment(self, question: str) -> Dict:
        """AIæ·±åº¦è¯„ä¼°é—®é¢˜å¤æ‚åº¦"""
        if not self.api_client:
            return {"score": 0, "reasoning": ""}
        
        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹é—®é¢˜çš„å¤æ‚åº¦ï¼ˆ1-5åˆ†ï¼Œ1æœ€ç®€å•ï¼Œ5æœ€å¤æ‚ï¼‰ï¼š

é—®é¢˜ï¼š{question}

è¯„ä¼°ç»´åº¦ï¼š
1. è®¤çŸ¥è´Ÿè·ï¼šéœ€è¦å¤šå°‘èƒŒæ™¯çŸ¥è¯†
2. æ¨ç†æ·±åº¦ï¼šéœ€è¦å¤šå°‘å±‚æ¨ç†
3. åˆ›æ–°ç¨‹åº¦ï¼šéœ€è¦å¤šå°‘åˆ›æ–°æ€è€ƒ
4. ç»¼åˆæ€§ï¼šæ¶‰åŠå¤šå°‘ä¸ªé¢†åŸŸ

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "score": æ•°å­—(1-5),
    "reasoning": "è¯„ä¼°ç†ç”±"
}}
"""
        
        try:
            response = await self.api_client.get_response(prompt, temperature=0.3)
            
            # è§£æå“åº”
            import json
            if '{' in response and '}' in response:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
                result = json.loads(json_str)
                
                return {
                    "score": float(result.get("score", 3)),
                    "reasoning": result.get("reasoning", "")
                }
            else:
                return {"score": 3, "reasoning": "AIè¯„ä¼°æ ¼å¼é”™è¯¯"}
                
        except Exception as e:
            logger.warning(f"AIè¯„ä¼°è§£æå¤±è´¥: {e}")
            return {"score": 3, "reasoning": f"AIè¯„ä¼°å¼‚å¸¸: {str(e)}"}
    
    def _calculate_final_score(self, question: str, text_metrics: float, keyword_metrics: float, 
                             structure_metrics: float, ai_metrics: Dict) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        base_score = (
            text_metrics * self.weights["length"] +
            keyword_metrics * self.weights["keywords"] +
            structure_metrics * self.weights["sentence_structure"] +
            self._assess_question_type(question) * self.weights["question_type"]
        )
        
        final_score = base_score + ai_metrics["score"] * self.weights["ai_assessment"]
        return final_score
    
    def _generate_reasoning(self, difficulty: int, text_metrics: float, 
                          keyword_metrics: float, structure_metrics: float, 
                          ai_metrics: Dict) -> str:
        """ç”Ÿæˆè¯„ä¼°æ¨ç†è¿‡ç¨‹"""
        difficulty_names = {
            1: "ç®€å•", 2: "åŸºç¡€", 3: "ä¸­ç­‰", 4: "å¤æ‚", 5: "æéš¾"
        }
        
        reasoning_parts = [
            f"é—®é¢˜éš¾åº¦è¯„ä¼°ä¸ºï¼š{difficulty_names[difficulty]}ï¼ˆ{difficulty}/5ï¼‰"
        ]
        
        # å„ç»´åº¦åˆ†æ
        if text_metrics >= 4:
            reasoning_parts.append(f"æ–‡æœ¬é•¿åº¦è¾ƒé•¿ï¼Œå¢åŠ ç†è§£éš¾åº¦")
        if keyword_metrics >= 4:
            reasoning_parts.append(f"åŒ…å«å¤šä¸ªå¤æ‚å…³é”®è¯")
        if structure_metrics >= 4:
            reasoning_parts.append(f"å¥å¼ç»“æ„å¤æ‚ï¼Œé€»è¾‘å…³ç³»å¤šå±‚")
        
        if ai_metrics["reasoning"]:
            reasoning_parts.append(f"AIæ·±åº¦åˆ†æï¼š{ai_metrics['reasoning']}")
        
        return "ï¼›".join(reasoning_parts)
    
    def get_temperature_distribution(self, routes: int) -> List[float]:
        """ä¸ºä¸åŒæ€è€ƒè·¯çº¿åˆ†é…æ¸©åº¦å€¼"""
        temp_config = self.config["temperature_range"]
        min_temp = temp_config["min"]
        max_temp = temp_config["max"]
        
        if routes <= 1:
            return [temp_config["default"]]
        
        # å‡åŒ€åˆ†å¸ƒæ¸©åº¦å€¼
        temperatures = []
        for i in range(routes):
            # çº¿æ€§æ’å€¼
            ratio = i / (routes - 1)
            temp = min_temp + ratio * (max_temp - min_temp)
            temperatures.append(round(temp, 2))
        
        return temperatures
    
    def get_branch_types(self, routes: int) -> List[str]:
        """ä¸ºä¸åŒæ€è€ƒè·¯çº¿åˆ†é…åˆ†æ”¯ç±»å‹"""
        branch_keys = list(BRANCH_TYPES.keys())
        
        # å¦‚æœè·¯çº¿æ•°å°‘äºåˆ†æ”¯ç±»å‹æ•°ï¼Œå¾ªç¯ä½¿ç”¨
        types = []
        for i in range(routes):
            types.append(branch_keys[i % len(branch_keys)])
        
        return types 